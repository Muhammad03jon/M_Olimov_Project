import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from category_encoders import TargetEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, roc_curve
from imblearn.over_sampling import RandomOverSampler

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title('üìû –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞')

# –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.markdown("""
    –≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∫–∞–∫–æ–π —Ç–∞—Ä–∏—Ñ–Ω—ã–π –ø–ª–∞–Ω –ª—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ —Ç–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ç–∞—Ä–∏—Ñ–Ω—ã–π –ø–ª–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞.
""")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data_url = "https://raw.githubusercontent.com/Muhammad03jon/M_Olimov_Project/refs/heads/master/data.csv"
df = pd.read_csv(data_url)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
df['ideal_plan'] = df['ideal_plan'].map({'Low': 0, 'Medium': 1, 'High': 2})

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
X_raw = df.drop('ideal_plan', axis=1)
y_raw = df['ideal_plan']

# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
categorical_features = X_raw.select_dtypes(include=['object']).columns
encoder = TargetEncoder(cols=categorical_features)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)

# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
X_train = encoder.fit_transform(X_train, y_train)
X_test = encoder.transform(X_test)

# –£–¥–∞–ª—è–µ–º —Å–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ TechSupport
drop_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'StreamingTV', 'StreamingMovies']
X_train = X_train.drop(columns=drop_cols)
X_test = X_test.drop(columns=drop_cols)

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
oversampler = RandomOverSampler(random_state=42)
X_train_scaled, y_train = oversampler.fit_resample(X_train_scaled, y_train)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
best_model = RandomForestClassifier(
    class_weight='balanced',
    max_depth=6, 
    min_samples_leaf=3, 
    min_samples_split=10, 
    n_estimators=50,
    random_state=42
)
best_model.fit(X_train_scaled, y_train)

# –í–∫–ª–∞–¥–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏
st.sidebar.subheader("üìä –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏")

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
accuracy_train = best_model.score(X_train_scaled, y_train)
accuracy_test = best_model.score(X_test_scaled, y_test)
y_pred_proba_train = best_model.predict_proba(X_train_scaled)
y_pred_proba_test = best_model.predict_proba(X_test_scaled)
roc_auc_train = roc_auc_score(y_train, y_pred_proba_train, multi_class="ovr")
roc_auc_test = roc_auc_score(y_test, y_pred_proba_test, multi_class="ovr")
y_pred_test = best_model.predict(X_test_scaled)
precision = precision_score(y_test, y_pred_test, average='macro')
recall = recall_score(y_test, y_pred_test, average='macro')
f1 = f1_score(y_test, y_pred_test, average='macro')

# –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ –≤ —Å–∞–π–¥–±–∞—Ä–µ
st.sidebar.write(f"**–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy) –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ:** {accuracy_train:.2f}")
st.sidebar.write(f"**–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy) –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ:** {accuracy_test:.2f}")
st.sidebar.write(f"**ROC AUC –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ:** {roc_auc_train:.2f}")
st.sidebar.write(f"**ROC AUC –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ:** {roc_auc_test:.2f}")
st.sidebar.write(f"**–ü—Ä–µ—Ü–∏–∑–∏–æ–Ω–Ω–æ—Å—Ç—å (Precision):** {precision:.2f}")
st.sidebar.write(f"**–ü–æ–ª–Ω–æ—Ç–∞ (Recall):** {recall:.2f}")
st.sidebar.write(f"**F1-–û—Ü–µ–Ω–∫–∞:** {f1:.2f}")

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
st.subheader("Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred_test)
fig, ax = plt.subplots(figsize=(7, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=['Low', 'Medium', 'High'], yticklabels=['Low', 'Medium', 'High'])
ax.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫')
st.pyplot(fig)

# ROC-–∫—Ä–∏–≤—ã–µ
st.subheader("ROC-–∫—Ä–∏–≤—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞")
fig, ax = plt.subplots(figsize=(7, 5))
for i in range(3):
    fpr, tpr, _ = roc_curve(y_test == i, y_pred_proba_test[:, i])
    ax.plot(fpr, tpr, label=f"Class {class_mapping[i]}")
ax.plot([0, 1], [0, 1], linestyle='--', color='gray')
ax.set_xlabel("False Positive Rate")
ax.set_ylabel("True Positive Rate")
ax.set_title("ROC-–∫—Ä–∏–≤—ã–µ")
ax.legend()
st.pyplot(fig)

# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
st.subheader("üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø–æ—Å–ª–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏)")
fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(pd.DataFrame(X_train_scaled).corr(), annot=True, fmt='.2f', cmap='coolwarm', ax=ax)
st.pyplot(fig)

# –í–≤–æ–¥ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
st.subheader("üîß –í–≤–æ–¥ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

# –ü–∞–Ω–µ–ª—å –≤–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö
new_data = {}

# –ü—Ä–∏–º–µ—Ä –ø–æ–ª–µ–π –≤–≤–æ–¥–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
columns = X_raw.columns
for col in columns:
    if X_raw[col].dtype == 'object':
        new_data[col] = st.selectbox(col, options=df[col].unique())
    else:
        new_data[col] = st.number_input(col, value=0.0)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ DataFrame
new_data_df = pd.DataFrame([new_data])

# –ö–æ–¥–∏—Ä—É–µ–º –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
new_data_encoded = encoder.transform(new_data_df)
new_data_scaled = scaler.transform(new_data_encoded)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
if st.button("–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–π —Ç–∞—Ä–∏—Ñ"):
    prediction = best_model.predict(new_data_scaled)
    st.write(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∏–¥–µ–∞–ª—å–Ω—ã–π —Ç–∞—Ä–∏—Ñ: {class_mapping[prediction[0]]}")
